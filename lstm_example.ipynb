{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import model_runner\n",
    "import embeddings\n",
    "import dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader to get training and test data from csv\n",
    "reader = dataset.csv_reader()\n",
    "\n",
    "# Open train.csv\n",
    "train_path = os.path.join(os.path.curdir, \"dataset\", \"train_small.csv\")\n",
    "reader.open_csv(train_path)\n",
    "train_reviews = reader.read(-1)\n",
    "\n",
    "# And test.csv\n",
    "test_path = os.path.join(os.path.curdir, \"dataset\", \"test_small.csv\")\n",
    "reader.open_csv(test_path)\n",
    "test_reviews = reader.read(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding text reviews to vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the embedder to use the glove-wiki-gigaword-50 embedding dictionary\n",
    "# https://github.com/piskvorky/gensim-data#:~:text=org/licenses/pddl/-,glove%2Dwiki%2Dgigaword%2D50,-400000\n",
    "review_embedder = embeddings.review_embedder()\n",
    "review_embedder.load_embedding_model(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dict denotes how review labels (strings) should be mapped to one-hot encodings (tensors)\n",
    "# Note that this mapping is for the original dataset,the dataset with remapped labels will look different\n",
    "review_label_mapping = {\n",
    "    \"1\": torch.tensor([1., 0., 0., 0., 0.]),\n",
    "    \"2\": torch.tensor([0., 1., 0., 0., 0.]),\n",
    "    \"3\": torch.tensor([0., 0., 1., 0., 0.]),\n",
    "    \"4\": torch.tensor([0., 0., 0., 1., 0.]),\n",
    "    \"5\": torch.tensor([0., 0., 0., 0., 1.]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating final embeddings\n",
    "# Based on this dict and the embedding scheme selected above (glove-wiki-gigaword-50),\n",
    "# we can embed our review text and labels to tensors\n",
    "# \n",
    "# Note that there are a few extra parameters to the embedder which aren't shown below:\n",
    "# \n",
    "# oov_feature: creates an extra label feature which is zero usually, except for when a word\n",
    "#   of a review can't be embedded because it is not contained in the word vector list\n",
    "#   of the chosen embedding scheme (the word is then \"out-of-vocab\"). When an OOV word\n",
    "#   is encountered in the review text and oov_feature is True (default), then the resulting\n",
    "#   word vector is a bunch of zeroes, plus a one in the oov_feature postition; when\n",
    "#   this happens and oov_feature is False, the word is simply skipped.\n",
    "# \n",
    "# title_body_feature: similar to oov_feature, this creates an extra label feature which is\n",
    "#   zero for words appearing in the title of the review and one for words appearing in the\n",
    "#   body of the review.\n",
    "# train_features, train_labels = review_embedder.embed_dataset_features_and_labels(train_reviews, review_label_mapping)\n",
    "# test_features, test_labels = review_embedder.embed_dataset_features_and_labels(test_reviews, review_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([23, 52]), torch.Size([1, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New sampler, which can run on the full dataset\n",
    "# TODO desc\n",
    "train_sampler = embeddings.review_embedder_sampler(train_reviews, review_embedder, review_label_mapping)\n",
    "test_sampler = embeddings.review_embedder_sampler(test_reviews, review_embedder, review_label_mapping)\n",
    "\n",
    "# Testing the samplers\n",
    "x_sample, y_sample = next(iter(train_sampler))\n",
    "x_sample.shape, y_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch has a built-in LSTM class which does what we need\n",
    "model = nn.LSTM(input_size=52, hidden_size=100, num_layers=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class review_LSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_classifier: nn.Module, batch_first: bool = True):\n",
    "        super().__init__()\n",
    "        self._LSTM = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=batch_first)\n",
    "        self._output_classifier = output_classifier\n",
    "        super().add_module(\"LSTM\", self._LSTM)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor | nn.utils.rnn.PackedSequence):\n",
    "        # Give the review data to the LSTM to munch on\n",
    "        output, (h_n, c_n) = self._LSTM.forward(x)\n",
    "        \n",
    "        # c_n is the cell state of the LSTM given all the data it has seen so far, and is supposed to\n",
    "        # represent the LSTM's overall interpretation of the data; it can be used as a feature vector\n",
    "        # for the output classifier to make a final class prediction. Feed it to the output classifier!\n",
    "        yhat = self._output_classifier.forward(c_n)\n",
    "        \n",
    "        # Return the results from the output classifier\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 52\n",
    "hidden_size = 100\n",
    "output_size = 5\n",
    "\n",
    "output_classifier = nn.Sequential(\n",
    "    nn.Linear(hidden_size, output_size),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "model = review_LSTM(input_size, hidden_size, output_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model optimizer objects\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model runner to handle training\n",
    "runner = model_runner.runner(model_name=\"LSTM_test\", model=model, optimizer=optim, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 10000/10000 [00:47<00:00, 209.32batches/s, batch loss=1.303, epoch train accuracy=47.66%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 437.73batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 10000/10000 [00:48<00:00, 206.75batches/s, batch loss=0.908, epoch train accuracy=48.44%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 440.53batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 10000/10000 [00:48<00:00, 208.18batches/s, batch loss=0.907, epoch train accuracy=48.43%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 451.02batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This epoch was the most accurate so far: validation accuracy = 43.09%. Saving model state...\n",
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 10000/10000 [00:50<00:00, 197.42batches/s, batch loss=1.874, epoch train accuracy=49.13%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:23<00:00, 431.88batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 10000/10000 [00:48<00:00, 206.46batches/s, batch loss=0.984, epoch train accuracy=49.70%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 441.54batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This epoch was the most accurate so far: validation accuracy = 43.46%. Saving model state...\n",
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 10000/10000 [00:48<00:00, 208.00batches/s, batch loss=0.934, epoch train accuracy=50.23%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 441.73batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 10000/10000 [00:48<00:00, 206.18batches/s, batch loss=1.798, epoch train accuracy=50.53%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 438.31batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 10000/10000 [00:48<00:00, 204.88batches/s, batch loss=0.905, epoch train accuracy=51.05%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 439.02batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 10000/10000 [00:48<00:00, 207.57batches/s, batch loss=0.936, epoch train accuracy=51.05%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 443.07batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 10000/10000 [00:48<00:00, 204.33batches/s, batch loss=1.885, epoch train accuracy=51.64%]\n",
      "Evaluating model accuracy: 100%|██████████| 10000/10000 [00:22<00:00, 441.98batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train that model!\n",
    "runner.train(train_sampler, test_sampler, num_epochs=10, autosave_interval_epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
