{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import model_runner\n",
    "import embeddings\n",
    "import dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader to get train and val data from csv\n",
    "reader = dataset.csv_reader()\n",
    "\n",
    "# Open formatted_train.csv\n",
    "train_path = os.path.join(os.path.curdir, \"dataset\", \"formatted_train.csv\")\n",
    "reader.open_csv(train_path, skip_header=True)\n",
    "train_reviews = reader.read(-1)\n",
    "\n",
    "# And formatted_val.csv\n",
    "val_path = os.path.join(os.path.curdir, \"dataset\", \"formatted_val.csv\")\n",
    "reader.open_csv(val_path, skip_header=True)\n",
    "val_reviews = reader.read(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding text reviews to vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the embedder to use the glove-wiki-gigaword-50 embedding dictionary\n",
    "# https://github.com/piskvorky/gensim-data#:~:text=org/licenses/pddl/-,glove%2Dwiki%2Dgigaword%2D50,-400000\n",
    "review_embedder = embeddings.review_embedder(embedding_model=\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dict denotes how review labels (strings) should be mapped to one-hot encodings (tensors)\n",
    "# Note that this mapping is for the original dataset,the dataset with remapped labels will look different\n",
    "review_label_mapping = {\n",
    "    \"negative\": torch.tensor([1., 0.]),\n",
    "    \"positive\": torch.tensor([0., 1.]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating final embeddings\n",
    "# Based on this dict and the embedding scheme selected above (glove-wiki-gigaword-50),\n",
    "# we can embed our review text and labels to tensors\n",
    "# \n",
    "# Note that there are a few extra parameters to the embedder which aren't shown below:\n",
    "# \n",
    "# oov_feature: creates an extra label feature which is zero usually, except for when a word\n",
    "#   of a review can't be embedded because it is not contained in the word vector list\n",
    "#   of the chosen embedding scheme (the word is then \"out-of-vocab\"). When an OOV word\n",
    "#   is encountered in the review text and oov_feature is True (default), then the resulting\n",
    "#   word vector is a bunch of zeroes, plus a one in the oov_feature postition; when\n",
    "#   this happens and oov_feature is False, the word is simply skipped.\n",
    "# \n",
    "# title_body_feature: similar to oov_feature, this creates an extra label feature which is\n",
    "#   zero for words appearing in the title of the review and one for words appearing in the\n",
    "#   body of the review.\n",
    "# train_features, train_labels = review_embedder.embed_dataset_features_and_labels(train_reviews, review_label_mapping)\n",
    "# test_features, test_labels = review_embedder.embed_dataset_features_and_labels(test_reviews, review_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[-0.9534, -0.1661, -0.7835,  ..., -0.4313,  0.0000,  0.0000],\n",
       "         [ 0.4162,  0.0087, -0.0458,  ..., -0.2288,  0.0000,  0.0000],\n",
       "         [-0.4248, -0.5238,  0.2449,  ...,  0.3188,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.1163,  0.5390, -0.3951,  ...,  0.0845,  0.0000,  1.0000],\n",
       "         [-0.2658,  0.5187,  0.0656,  ...,  1.2443,  0.0000,  1.0000],\n",
       "         [-0.2931,  0.3508,  1.1328,  ..., -0.3749,  0.0000,  1.0000]]), batch_sizes=tensor([50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "         50, 48, 48, 47, 45, 45, 45, 45, 45, 45, 45, 45, 43, 43, 41, 40, 40, 39,\n",
       "         38, 38, 38, 37, 36, 35, 35, 35, 35, 34, 34, 33, 33, 32, 30, 30, 30, 30,\n",
       "         30, 30, 30, 30, 30, 30, 30, 30, 29, 29, 29, 28, 27, 26, 26, 25, 25, 25,\n",
       "         25, 24, 24, 23, 23, 22, 20, 20, 20, 19, 19, 18, 18, 17, 16, 16, 16, 16,\n",
       "         16, 15, 15, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 11, 11, 11, 11,\n",
       "         11, 11, 11, 11, 11, 11, 10,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,\n",
       "          8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "          6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "          5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  2,  2,  1,  1]), sorted_indices=None, unsorted_indices=None),\n",
       " torch.Size([50, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New sampler, which can run on the full dataset\n",
    "# TODO desc\n",
    "train_sampler = embeddings.batched_review_embedder_sampler(train_reviews, review_embedder, review_label_mapping, batch_size=50)\n",
    "val_sampler = embeddings.batched_review_embedder_sampler(val_reviews, review_embedder, review_label_mapping, batch_size=50)\n",
    "\n",
    "# Testing the samplers\n",
    "x_sample, y_sample = next(iter(train_sampler))\n",
    "x_sample, y_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class review_LSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_classifier: nn.Module):\n",
    "        super().__init__()\n",
    "        self._LSTM = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self._output_classifier = output_classifier\n",
    "        self._hidden_size = hidden_size\n",
    "        super().add_module(\"LSTM\", self._LSTM)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor | nn.utils.rnn.PackedSequence):\n",
    "        # Give the review data to the LSTM to munch on\n",
    "        output, (h_n, c_n) = self._LSTM.forward(x)\n",
    "        \n",
    "        # c_n is the cell state of the LSTM given all the data it has seen so far, and is supposed to\n",
    "        # represent the LSTM's overall interpretation of the data; it can be used as a feature vector\n",
    "        # for the output classifier to make a final class prediction. Reshape it to [batch_size x hidden_size],\n",
    "        # then feed it to the output classifier\n",
    "        c_n = torch.reshape(c_n, (-1, self._hidden_size))\n",
    "        yhat = self._output_classifier.forward(c_n)\n",
    "        \n",
    "        # Return the results from the output classifier\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 52\n",
    "hidden_size = 100\n",
    "output_size = 2\n",
    "\n",
    "output_classifier = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "model = review_LSTM(input_size, hidden_size, output_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model optimizer objects\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model runner to handle training\n",
    "runner = model_runner.runner(model_name=\"LSTM_test_full_formatted_dataset\", model=model, optimizer=optim, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 38400/38400 [14:18<00:00, 44.74batches/s, batch loss=0.323, epoch train accuracy=76.95%]\n",
      "Evaluating model accuracy: 100%|██████████| 9600/9600 [02:46<00:00, 57.83batches/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This epoch was the most accurate so far: validation accuracy = 84.62%. Saving model state...\n",
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 38400/38400 [29:32<00:00, 21.67batches/s, batch loss=0.375, epoch train accuracy=85.23%]    \n",
      "Evaluating model accuracy: 100%|██████████| 9600/9600 [02:40<00:00, 59.69batches/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This epoch was the most accurate so far: validation accuracy = 86.52%. Saving model state...\n",
      "Reached epoch save interval, saving model state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:   0%|          | 100/38400 [00:03<19:57, 31.99batches/s, batch loss=0.398, epoch train accuracy=86.32%] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\lstm_example.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/will/Documents/ECE539%20Final%20Project/ECE539-Final-Project/lstm_example.ipynb#Y106sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train that model!\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/will/Documents/ECE539%20Final%20Project/ECE539-Final-Project/lstm_example.ipynb#Y106sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m runner\u001b[39m.\u001b[39;49mtrain(train_sampler, val_sampler, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, autosave_interval_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\model_runner.py:181\u001b[0m, in \u001b[0;36mrunner.train\u001b[1;34m(self, train_batch_iterator, val_batch_iterator, num_epochs, autosave_interval_epochs)\u001b[0m\n\u001b[0;32m    177\u001b[0m starting_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch\n\u001b[0;32m    179\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m    180\u001b[0m     \u001b[39m# Train the epoch\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(train_batch_iterator)\n\u001b[0;32m    183\u001b[0m     \u001b[39m# Measure model accuracy against the validation dataset\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     val_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier_accuracy_score(val_batch_iterator)\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\model_runner.py:153\u001b[0m, in \u001b[0;36mrunner._train_epoch\u001b[1;34m(self, train_batch_iterator)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39m# tqdm gives a nice status bar to show the epoch progress\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(train_batch_iterator, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Epoch \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatches\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m tepoch:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mfor\u001b[39;49;00m x_batch, y_batch \u001b[39min\u001b[39;49;00m tepoch:\n\u001b[0;32m    154\u001b[0m         \u001b[39m# Batch train\u001b[39;49;00m\n\u001b[0;32m    155\u001b[0m         batch_loss, batch_accurate_predictions, batch_samples \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_batch(x_batch, y_batch)\n\u001b[0;32m    157\u001b[0m         \u001b[39m# Update statistics\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\.venv\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\embeddings.py:267\u001b[0m, in \u001b[0;36mbatched_review_embedder_sampler.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mfor\u001b[39;00m sample_i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_size):\n\u001b[0;32m    265\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m         \u001b[39m# Fetch one sample\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m         batch_samples\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler))\n\u001b[0;32m    269\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m         \u001b[39m# Out of samples! Finish the current batch if there are any samples in it, or exit if not\u001b[39;00m\n\u001b[0;32m    271\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch_samples) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\embeddings.py:226\u001b[0m, in \u001b[0;36mreview_embedder_sampler.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mTuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Check to see if another chunk of data needs to be loaded\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chunk_read_location \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_chunk_embedded_reviews):\n\u001b[1;32m--> 226\u001b[0m         chunk_load_success \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_next_chunk()\n\u001b[0;32m    227\u001b[0m         \u001b[39m# Exit if no new reviews were found to embed\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk_load_success:\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\embeddings.py:212\u001b[0m, in \u001b[0;36mreview_embedder_sampler._load_next_chunk\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Fetch the next chunk of data\u001b[39;00m\n\u001b[0;32m    211\u001b[0m next_chunk_reviews \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reviews[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_review_read_location : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_review_read_location \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chunk_size]\n\u001b[1;32m--> 212\u001b[0m next_chunk_embedded_reviews \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedder\u001b[39m.\u001b[39;49membed_dataset_features_and_labels(next_chunk_reviews, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_review_label_mapping, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oov_feature, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_title_body_feature)\n\u001b[0;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_chunk_embedded_reviews \u001b[39m=\u001b[39m next_chunk_embedded_reviews\n\u001b[0;32m    214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chunk_read_location \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\embeddings.py:120\u001b[0m, in \u001b[0;36mreview_embedder.embed_dataset_features_and_labels\u001b[1;34m(self, reviews, review_label_mapping, oov_feature, title_body_feature)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(reviews, \u001b[39m\"\u001b[39m\u001b[39mEmbedding features\u001b[39m\u001b[39m\"\u001b[39m, position\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreviews\u001b[39m\u001b[39m\"\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m treviews:\n\u001b[0;32m    119\u001b[0m     \u001b[39mfor\u001b[39;00m review \u001b[39min\u001b[39;00m treviews:\n\u001b[1;32m--> 120\u001b[0m         features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_review_features(review, oov_feature, title_body_feature)\n\u001b[0;32m    122\u001b[0m         \u001b[39m# Some reviews have no alpha title or body, which models don't like; if one of\u001b[39;00m\n\u001b[0;32m    123\u001b[0m         \u001b[39m# these is found, skip it!\u001b[39;00m\n\u001b[0;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\embeddings.py:84\u001b[0m, in \u001b[0;36mreview_embedder.embed_review_features\u001b[1;34m(self, review, oov_feature, title_body_feature, dtype)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_review_features\u001b[39m(\u001b[39mself\u001b[39m, review: dataset\u001b[39m.\u001b[39mreview, oov_feature \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, title_body_feature \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m     82\u001b[0m     \u001b[39m# Embed the title and the body\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     title_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embed_text_tensor(review\u001b[39m.\u001b[39mtitle, oov_feature)\n\u001b[1;32m---> 84\u001b[0m     body_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_text_tensor(review\u001b[39m.\u001b[39;49mbody, oov_feature)\n\u001b[0;32m     86\u001b[0m     \u001b[39m# Add an extra feature to denote title vs. body, if desired\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m title_body_feature:\n\u001b[0;32m     88\u001b[0m         \u001b[39m# Add zeros as a feature for the title\u001b[39;00m\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\embeddings.py:73\u001b[0m, in \u001b[0;36mreview_embedder._embed_text_tensor\u001b[1;34m(self, text, oov_feature)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_text_tensor\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, oov_feature \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m---> 73\u001b[0m     embedded_text \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embed_text_vectors(text, oov_feature))\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(embedded_text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     75\u001b[0m         \u001b[39mreturn\u001b[39;00m  np\u001b[39m.\u001b[39mconcatenate(embedded_text, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\will\\Documents\\ECE539 Final Project\\ECE539-Final-Project\\embeddings.py:58\u001b[0m, in \u001b[0;36mreview_embedder._embed_text_vectors\u001b[1;34m(self, text, oov_feature)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m oov_feature:\n\u001b[0;32m     56\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m         \u001b[39m# Add a zero out-of-vocab flag if the embedding could be found\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m         \u001b[39myield\u001b[39;00m np\u001b[39m.\u001b[39;49mconcatenate([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_model[word], np\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m)], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mreshape([\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     59\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m         \u001b[39m# Add a one out-of-vocab flag if the embedding couldn't be found\u001b[39;00m\n\u001b[0;32m     61\u001b[0m         \u001b[39myield\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate([np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_vector_length), np\u001b[39m.\u001b[39mones(\u001b[39m1\u001b[39m)], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mreshape([\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train that model!\n",
    "runner.train(train_sampler, val_sampler, num_epochs=10, autosave_interval_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.21902190219021903,\n",
       "  0.2508250825082508,\n",
       "  0.26752675267526754,\n",
       "  0.24542454245424541,\n",
       "  0.2737273727372737,\n",
       "  0.23542354235423543,\n",
       "  0.27262726272627263,\n",
       "  0.2861286128612861,\n",
       "  0.2591259125912591,\n",
       "  0.29812981298129815,\n",
       "  0.2765276527652765,\n",
       "  0.29572957295729574,\n",
       "  0.34493449344934496,\n",
       "  0.37013701370137014,\n",
       "  0.3852385238523852,\n",
       "  0.40594059405940597,\n",
       "  0.4146414641464146,\n",
       "  0.42674267426742674,\n",
       "  0.43504350435043504,\n",
       "  0.4452445244524452,\n",
       "  0.45104510451045104,\n",
       "  0.446044604460446,\n",
       "  0.45934593459345935,\n",
       "  0.4667466746674667,\n",
       "  0.4673467346734673,\n",
       "  0.47664766476647663,\n",
       "  0.48444844484448446,\n",
       "  0.48434843484348433,\n",
       "  0.49134913491349136,\n",
       "  0.49704970497049705,\n",
       "  0.5022502250225023,\n",
       "  0.5052505250525052,\n",
       "  0.5104510451045104,\n",
       "  0.5104510451045104,\n",
       "  0.5163516351635163,\n",
       "  0.5221522152215221,\n",
       "  0.5275527552755276,\n",
       "  0.5318531853185319,\n",
       "  0.5287528752875288,\n",
       "  0.5398539853985399,\n",
       "  0.5472547254725473,\n",
       "  0.5508550855085509,\n",
       "  0.005842424242424245,\n",
       "  0.005907070707070706,\n",
       "  0.5954545454545455,\n",
       "  0.5973737373737373,\n",
       "  0.5985858585858586,\n",
       "  0.6006060606060606,\n",
       "  0.6013131313131314,\n",
       "  0.6027272727272728,\n",
       "  0.6035353535353535,\n",
       "  0.6048484848484849,\n",
       "  0.6054545454545455,\n",
       "  0.6055555555555555,\n",
       "  0.6070707070707071,\n",
       "  0.6062626262626263,\n",
       "  0.6072727272727273,\n",
       "  0.6087878787878788,\n",
       "  0.6094949494949495,\n",
       "  0.6094949494949495,\n",
       "  0.6105050505050506,\n",
       "  0.6107070707070708,\n",
       "  0.6112121212121212,\n",
       "  0.6111111111111112,\n",
       "  0.6117171717171718,\n",
       "  0.6111111111111112,\n",
       "  0.6117171717171718,\n",
       "  0.613030303030303],\n",
       " [0.2381,\n",
       "  0.2649,\n",
       "  0.2618,\n",
       "  0.2308,\n",
       "  0.2829,\n",
       "  0.2457,\n",
       "  0.2649,\n",
       "  0.2953,\n",
       "  0.2707,\n",
       "  0.3251,\n",
       "  0.2924,\n",
       "  0.3051,\n",
       "  0.37,\n",
       "  0.3407,\n",
       "  0.3761,\n",
       "  0.3989,\n",
       "  0.3688,\n",
       "  0.4051,\n",
       "  0.3904,\n",
       "  0.4079,\n",
       "  0.407,\n",
       "  0.4091,\n",
       "  0.4258,\n",
       "  0.4064,\n",
       "  0.4213,\n",
       "  0.4216,\n",
       "  0.4072,\n",
       "  0.4309,\n",
       "  0.4258,\n",
       "  0.4346,\n",
       "  0.4229,\n",
       "  0.4283,\n",
       "  0.4259,\n",
       "  0.4342,\n",
       "  0.4339,\n",
       "  0.4264,\n",
       "  0.4077,\n",
       "  0.4333,\n",
       "  0.431,\n",
       "  0.4293,\n",
       "  0.4314,\n",
       "  0.4347,\n",
       "  0.004362999999999999,\n",
       "  0.004339000000000001,\n",
       "  0.4349,\n",
       "  0.4346,\n",
       "  0.4344,\n",
       "  0.435,\n",
       "  0.4335,\n",
       "  0.4341,\n",
       "  0.4346,\n",
       "  0.4355,\n",
       "  0.4349,\n",
       "  0.4349,\n",
       "  0.4348,\n",
       "  0.4348,\n",
       "  0.4349,\n",
       "  0.434,\n",
       "  0.4341,\n",
       "  0.4342,\n",
       "  0.4344,\n",
       "  0.4344,\n",
       "  0.4346,\n",
       "  0.4338,\n",
       "  0.4339,\n",
       "  0.4359,\n",
       "  0.4345,\n",
       "  0.4357])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner._train_acc_history, runner._val_acc_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
